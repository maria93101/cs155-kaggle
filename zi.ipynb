{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "\n",
    "def load_data(filename, skiprows = 1):\n",
    "    '''   \n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\\n\",\n",
    "\n",
    "    Inputs:\n",
    "    filename: given as a string.\n",
    "    Outputs:\\n\",\n",
    "    Data contained in the file, returned as a numpy ndarray\\n\",\n",
    "    '''\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as k_back\n",
    "\n",
    "\n",
    "# define the AUC metric being used in the competition\n",
    "# this function can be used in Keras' Sequential Model compilation only\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    k_back.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data(\"data/train_2008.csv\")\n",
    "test = load_data(\"data/test_2008.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = train[:,train.shape[1]-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refineInput(X, y_train_new, section, total):\n",
    "    X_traincopy = X.copy()\n",
    "    y_traincopy = y_train_new.copy()\n",
    "    X_train = X_traincopy[:,3:]\n",
    "    num = X_traincopy.shape[0]/total\n",
    "    X_test = X_traincopy[int(num*section):int(num*(section+1)),:]\n",
    "    X_train = X_traincopy[:int(num*section),:]\n",
    "    X_train = np.concatenate((X_train, X_traincopy[int(num*(section+1)):,:]))\n",
    "    \n",
    "    y_test = y_traincopy[int(num*section):int(num*(section+1)),:]\n",
    "    y_train = y_traincopy[:int(num*section),:]\n",
    "    y_train = np.concatenate((y_train, y_traincopy[int(num*(section+1)):,:]))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8405000e+04,  1.1000000e+01,  2.0080000e+03,  1.0000000e+00,\n",
       "         2.0100000e+02,  0.0000000e+00,  2.0000000e+00,  1.0000000e+00,\n",
       "         1.0000000e+00, -1.0000000e+00,  1.0000000e+00, -2.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,  4.3738474e+07,\n",
       "         1.0000000e+00,  5.0000000e+00,  4.0000000e+00,  5.0000000e+00,\n",
       "         2.0000000e+00,  1.0000000e+00,  3.0000000e+00,  8.3001000e+04,\n",
       "         2.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  2.0000000e+00,  3.3000000e+01,  1.7000000e+01,\n",
       "         1.9500000e+04,  1.1500000e+02,  4.0000000e+00,  1.0000000e+00,\n",
       "         0.0000000e+00,  2.0000000e+00,  0.0000000e+00,  1.0000000e+00,\n",
       "         4.0000000e+00,  1.8000000e+01,  0.0000000e+00,  6.0000000e+00,\n",
       "        -1.0000000e+00,  2.0000000e+00,  2.0000000e+00,  2.0000000e+00,\n",
       "         3.9000000e+01,  2.0000000e+00, -1.0000000e+00,  9.0000000e+00,\n",
       "         1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "         2.0000000e+00,  7.0000000e+00,  2.0000000e+00,  5.7000000e+01,\n",
       "         5.7000000e+01,  5.7000000e+01,  1.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,  2.0000000e+00,\n",
       "        -1.0000000e+00,  4.0000000e+01, -1.0000000e+00, -1.0000000e+00,\n",
       "         4.0000000e+01, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  2.0000000e+00, -1.0000000e+00,  2.0000000e+00,\n",
       "        -1.0000000e+00,  4.0000000e+01, -1.0000000e+00,  4.0000000e+01,\n",
       "        -1.0000000e+00,  2.0000000e+00,  5.0000000e+00,  5.0000000e+00,\n",
       "        -1.0000000e+00,  2.0000000e+00,  3.0000000e+00,  5.0000000e+00,\n",
       "         2.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  1.0000000e+00, -1.0000000e+00,  1.8000000e+01,\n",
       "         1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  4.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  1.0000000e+00,  2.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  4.0000000e+00,  4.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  2.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  1.0000000e+00,  2.0000000e+00,  4.0000000e+00,\n",
       "        -1.0000000e+00,  1.0000000e+00,  6.0000000e+00, -1.0000000e+00,\n",
       "         3.8000000e+01, -1.0000000e+00,  1.4000000e+01, -1.0000000e+00,\n",
       "         1.0000000e+00,  9.0000000e+00, -1.0000000e+00,  3.0000000e+00,\n",
       "        -1.0000000e+00,  2.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "         1.0000000e+00,  0.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  0.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  0.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "         0.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  2.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "         2.0000000e+00,  4.3738474e+07,  0.0000000e+00,  0.0000000e+00,\n",
       "         4.3738474e+07,  3.9444386e+07,  1.0000000e+00,  1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  1.0000000e+00,  0.0000000e+00, -1.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         1.0000000e+00,  0.0000000e+00,  1.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.0000000e+00,\n",
       "         1.0000000e+00,  1.0000000e+00,  0.0000000e+00,  1.0000000e+00,\n",
       "         0.0000000e+00,  1.0000000e+00,  1.0000000e+00,  0.0000000e+00,\n",
       "         1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  0.0000000e+00,\n",
       "         1.0000000e+00,  0.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  0.0000000e+00,  1.0000000e+00,\n",
       "         1.0000000e+00,  4.2322000e+04,  1.0000000e+00,  1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  0.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "         1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  3.9444386e+07,\n",
       "         7.6900000e+03,  4.2200000e+03, -1.0000000e+00, -1.0000000e+00,\n",
       "         1.4000000e+01, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  0.0000000e+00, -1.0000000e+00,\n",
       "         4.0000000e+00, -1.0000000e+00,  1.0000000e+00, -1.0000000e+00,\n",
       "         5.0000000e+01,  0.0000000e+00,  1.0000000e+00,  0.0000000e+00,\n",
       "         1.0000000e+00,  2.0000000e+00,  2.0000000e+00,  2.0000000e+00,\n",
       "         2.0000000e+00,  2.0000000e+00,  2.0000000e+00,  2.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00],\n",
       "       [ 1.8406000e+04,  1.1000000e+01,  2.0080000e+03,  1.0000000e+00,\n",
       "         2.0100000e+02,  0.0000000e+00,  2.0000000e+00,  1.0000000e+00,\n",
       "         1.0000000e+00, -1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,  3.3167831e+07,\n",
       "         1.0000000e+00,  1.0000000e+00,  7.0000000e+00,  5.0000000e+00,\n",
       "         2.0000000e+00,  1.0000000e+00,  3.0000000e+00,  8.3001000e+04,\n",
       "         2.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  2.0000000e+00,  3.4000000e+01,  2.6000000e+01,\n",
       "         1.9820000e+04,  1.6300000e+02,  2.0000000e+00,  1.0000000e+00,\n",
       "         0.0000000e+00,  6.0000000e+00,  2.2000000e+02,  2.0000000e+00,\n",
       "        -1.0000000e+00,  5.4000000e+01,  0.0000000e+00,  6.0000000e+00,\n",
       "        -1.0000000e+00,  2.0000000e+00,  2.0000000e+00,  2.0000000e+00,\n",
       "         4.0000000e+01,  2.0000000e+00, -1.0000000e+00,  9.0000000e+00,\n",
       "         1.0000000e+00,  0.0000000e+00,  0.0000000e+00,  2.0000000e+00,\n",
       "         2.0000000e+00,  7.0000000e+00,  2.0000000e+00,  5.7000000e+01,\n",
       "         5.7000000e+01,  5.7000000e+01,  1.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  1.0000000e+00,  4.0000000e+00,  2.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  2.0000000e+00, -1.0000000e+00,\n",
       "         2.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,  2.0000000e+00,\n",
       "         2.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,  1.0000000e+00,\n",
       "         6.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  1.0000000e+00, -1.0000000e+00,\n",
       "         1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.2000000e+01,\n",
       "         1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  1.0000000e+00, -1.0000000e+00,  0.0000000e+00,\n",
       "         2.0000000e+00,  2.0000000e+00,  1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,  1.2000000e+01,\n",
       "         2.0000000e+00,  3.0000000e+00,  1.1000000e+01, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  4.0000000e+00,  2.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  1.0000000e+00,  2.0000000e+00,  4.0000000e+00,\n",
       "        -1.0000000e+00,  1.0000000e+00,  6.0000000e+00, -1.0000000e+00,\n",
       "         1.0000000e+01, -1.0000000e+00,  2.1000000e+01, -1.0000000e+00,\n",
       "        -1.0000000e+00,  4.0000000e+00, -1.0000000e+00,  9.0000000e+00,\n",
       "        -1.0000000e+00,  6.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "        -1.0000000e+00,  0.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  0.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  0.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "         0.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  3.3167831e+07,  0.0000000e+00,  0.0000000e+00,\n",
       "         3.3167831e+07,  3.2088889e+07, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  1.0000000e+00,  0.0000000e+00, -1.0000000e+00,\n",
       "         0.0000000e+00,  5.0000000e+01,  0.0000000e+00,  0.0000000e+00,\n",
       "         1.0000000e+00,  0.0000000e+00,  1.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  0.0000000e+00,  4.1000000e+01,\n",
       "         4.1000000e+01, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  5.4181000e+04,  1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  2.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  0.0000000e+00,\n",
       "         1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  3.2150518e+07,\n",
       "         3.5700000e+03,  7.7500000e+03, -1.0000000e+00, -1.0000000e+00,\n",
       "         4.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  0.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
       "         5.0000000e+01,  5.0000000e+01,  1.0000000e+00,  1.0000000e+00,\n",
       "         1.0000000e+00,  2.0000000e+00,  1.0000000e+00,  2.0000000e+00,\n",
       "         2.0000000e+00,  2.0000000e+00,  2.0000000e+00,  1.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[10:12,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 1050)              402150    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 1050)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1050)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 1051      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 403,201\n",
      "Trainable params: 403,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "64667/64667 [==============================] - 25s 384us/step - loss: 0.7446 - acc: 0.2554\n",
      "Epoch 2/10\n",
      "64667/64667 [==============================] - 24s 367us/step - loss: 0.7446 - acc: 0.2554\n",
      "Epoch 3/10\n",
      "64667/64667 [==============================] - 23s 356us/step - loss: 0.7446 - acc: 0.2554\n",
      "Epoch 4/10\n",
      "64667/64667 [==============================] - 26s 405us/step - loss: 0.7446 - acc: 0.2554\n",
      "Epoch 5/10\n",
      "64667/64667 [==============================] - 25s 383us/step - loss: 0.7446 - acc: 0.2554\n",
      "Epoch 6/10\n",
      "64667/64667 [==============================] - 27s 420us/step - loss: 0.7446 - acc: 0.2554\n",
      "Epoch 7/10\n",
      "64667/64667 [==============================] - 30s 461us/step - loss: 0.7446 - acc: 0.2554\n",
      "Epoch 8/10\n",
      "64667/64667 [==============================] - 33s 506us/step - loss: 0.7446 - acc: 0.2554\n",
      "Epoch 9/10\n",
      "64256/64667 [============================>.] - ETA: 0s - loss: 0.7448 - acc: 0.2552"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    #Flatten(input_shape=(28,28,)),  # Use np.reshape instead of this in hw\\n\",\n",
    "    Dense(1050, input_shape=(382,)), \n",
    "    Activation('relu'), \n",
    "    Dropout(0.3),        \n",
    "    Dense(1),\n",
    "    Activation('softmax')\n",
    "    ])\n",
    "model.compile(loss='squared_hinge',optimizer='adam', metrics=['accuracy'], verbose=1)\n",
    "model.build()\n",
    "    \n",
    "model.summary()\n",
    "fit = model.fit(X_train, y_train_new, batch_size=32, epochs=3, verbose = 1)\n",
    "## Printing the accuracy of our model, according to the loss function specified in model.compile above\\n\",\n",
    "score = model.evaluate(X_train, y_train_new)\n",
    "print(score)\n",
    "\n",
    "predict = model.predict(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64667/64667 [==============================] - 6s 88us/step\n",
      "[0.7446147184799109, 0.25538528152008916]\n"
     ]
    }
   ],
   "source": [
    "X_train = train[:,:train.shape[1]-1]\n",
    "#X_train = X_train[:,3:]\n",
    "score = model.evaluate(X_train, y_train_new)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55429, 382) (55429, 1)\n",
      "test 0.24569092497610678\n",
      "0.2724278963027511\n",
      "train 0.22834767175919446\n",
      "0.18382215233471133\n",
      "(55429, 382) (55429, 1)\n",
      "test 0.24093237515124077\n",
      "0.2681201444441733\n",
      "train 0.23018821503929998\n",
      "0.19051035161426588\n",
      "(55429, 382) (55429, 1)\n",
      "test 0.25700321766530987\n",
      "0.2778615252214859\n",
      "train 0.22652252366797798\n",
      "0.18272851154799685\n",
      "(55429, 382) (55429, 1)\n",
      "test 0.245460970566455\n",
      "0.2685809975186084\n",
      "train 0.2296259653046281\n",
      "0.18563403573404924\n",
      "(55429, 382) (55429, 1)\n",
      "test 0.25148736244195025\n",
      "0.2596522686880114\n",
      "train 0.2281081888271741\n",
      "0.18682707332699167\n",
      "(55429, 382) (55429, 1)\n",
      "test 0.2436451850078395\n",
      "0.26706897174306\n",
      "train 0.22927443062407538\n",
      "0.1870351438697503\n",
      "(55428, 382) (55428, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-a4b5e2382b90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mregr_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mregr_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mregr_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mregr_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "N = 7\n",
    "for i in range(7):\n",
    "    y_train_new = train[:,train.shape[1]-1:]\n",
    "    X_train = train[:,:train.shape[1]-1]\n",
    "    X_train, x_test, y_train, y_test = refineInput(X_train, y_train_new, i, 7)\n",
    "    # Fit regression model\n",
    "    regr_1 = DecisionTreeRegressor(max_depth=7)\n",
    "    regr_2 = DecisionTreeRegressor(max_depth=10)\n",
    "    regr_1.fit(X_train, y_train)\n",
    "    regr_2.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_1 = regr_1.predict(x_test)\n",
    "    y_2 = regr_2.predict(x_test)\n",
    "    \n",
    "    y_t_1 = regr_1.predict(X_train)\n",
    "    y_t_2 = regr_2.predict(X_train)\n",
    "    \n",
    "    \n",
    "    print(\"test\", roc_auc_score(y_test, y_1))\n",
    "    print(roc_auc_score(y_test, y_2)  )\n",
    "    \n",
    "    print(\"train\", roc_auc_score(y_train ,y_t_1 ))\n",
    "    print(roc_auc_score(y_train,y_t_2)  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.6495285165738481\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.67265743304632\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7105775482162505\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7111891221547529\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7106737243649933\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7096140282336539\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7107624049178218\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7100304228937689\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.6495285165738481\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.6727212073944292\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7160117290495421\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7176054498413142\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7280041109288341\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7330862421321444\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7358141051051847\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7356415776985139\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.6495285165738481\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.67302066822549\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7120636482451321\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7174596823900998\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7261815017922354\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7344172273101807\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7376158572104058\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7380999561302143\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.6495285165738481\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.6728026191027029\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7153633064760047\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7177160816093817\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7281324338291907\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7320821541626692\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7363082456309794\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7398474669198977\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.6495285165738481\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.6729705980143131\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7120265002934009\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7174919723751062\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7282070911008348\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7333425593512616\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7364431509510999\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7383638808012776\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.6495285165738481\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.6728217269748298\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7130498915279591\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7182787139394667\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55428, 382) (55428, 1)\n",
      "0.7265510836750301\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n",
      "(55429, 382) (55429, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-5983752121d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mregr_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mregr_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;31m#regr_2.fit(X_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 326\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "N = 7\n",
    "res = []\n",
    "for depth in range(1, 10):\n",
    "    row = []\n",
    "    for nodes in range(2, 10):\n",
    "        avg_test = 0\n",
    "        avg_train = 0\n",
    "        for i in range(7):\n",
    "            y_train_new = train[:,train.shape[1]-1:]\n",
    "            X_train = train[:,:train.shape[1]-1]\n",
    "            X_train, x_test, y_train, y_test = refineInput(X_train, y_train_new, i, 7)\n",
    "            # Fit regression model\n",
    "            y_train = np.ravel(y_train)\n",
    "            regr_1 = RandomForestRegressor(max_depth=depth, max_leaf_nodes = nodes)\n",
    "            regr_1.fit(X_train, y_train)\n",
    "            #regr_2.fit(X_train, y_train)\n",
    "\n",
    "            # Predict\n",
    "            y_1 = regr_1.predict(x_test)\n",
    "            #y_2 = regr_2.predict(x_test)\n",
    "\n",
    "            y_t_1 = regr_1.predict(X_train)\n",
    "            #y_t_2 = regr_2.predict(X_train)\n",
    "\n",
    "            avg_test += roc_auc_score(y_test, y_1)\n",
    "            avg_train += roc_auc_score(y_train ,y_t_1 )\n",
    "            #print(\"test\", roc_auc_score(y_test, y_1))\n",
    "            #print(roc_auc_score(y_test, y_2)  )\n",
    "\n",
    "            #print(\"train\", roc_auc_score(y_train ,y_t_1 ))\n",
    "            #print(roc_auc_score(y_train,y_t_2)  )\n",
    "        avg_test /= 7\n",
    "        avg_train /= 7\n",
    "        row.append(avg_test)\n",
    "        print(avg_test)\n",
    "    res.append(row)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054374085090559646\n",
      "0.13803736922642404\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(16000, 0), dtype=float64)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[:,3:]\n",
    "y_train_new = train[:,train.shape[1]-1:]\n",
    "X_train = train[:,:train.shape[1]-1]\n",
    "X_train = X_train[:,3:]\n",
    "#regr_2 = DecisionTreeRegressor(max_depth=10)\n",
    "#regr_2.fit(X_train, y_train_new)\n",
    "#y_2 = regr_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_data(\"data/test_2008.csv\")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_test = test[:,3:]\n",
    "predictions = xgb.predict(X_test)\n",
    "predictions = predictions.reshape(16000, 1)\n",
    "\n",
    "mmscaler = MinMaxScaler()\n",
    "new_pred = mmscaler.fit_transform(predictions)\n",
    "ids = test[:,:1]\n",
    "ids = ids.astype(int)\n",
    "new_pred = new_pred.astype(float)\n",
    "test = np.concatenate((ids, predictions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = predictions.astype(float)\n",
    "test = np.concatenate((ids, predictions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('submission.csv', test, delimiter=',', fmt='%1.10f', header = 'id,target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.27371597]\n",
      " [0.11366704]\n",
      " [0.1329549 ]\n",
      " ...\n",
      " [0.24748915]\n",
      " [0.02386603]\n",
      " [0.2097044 ]]\n",
      "[[0.29579499]\n",
      " [0.15811621]\n",
      " [0.17470819]\n",
      " ...\n",
      " [0.27323392]\n",
      " [0.08086675]\n",
      " [0.24073036]]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(new_pred)\n",
    "for i in predictions:\n",
    "    if i[0] <0:\n",
    "        i[0] = 0\n",
    "    elif i[0]>1:\n",
    "        i[0] = 1\n",
    "        \n",
    "print(min(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378'] []\nexpected f138, f3, f372, f283, f270, f0, f285, f189, f228, f125, f142, f290, f100, f39, f131, f27, f223, f84, f32, f281, f309, f280, f59, f98, f278, f259, f145, f73, f119, f211, f41, f203, f250, f307, f105, f217, f164, f5, f22, f135, f25, f21, f102, f86, f184, f359, f109, f15, f361, f71, f330, f180, f128, f114, f196, f92, f120, f284, f53, f200, f364, f368, f374, f51, f95, f267, f188, f305, f231, f122, f323, f78, f50, f261, f91, f107, f319, f121, f67, f327, f242, f28, f87, f143, f148, f80, f178, f4, f258, f300, f191, f249, f170, f2, f150, f64, f89, f19, f99, f253, f192, f350, f48, f224, f141, f334, f336, f166, f256, f101, f234, f240, f357, f333, f110, f265, f213, f58, f177, f8, f154, f54, f326, f317, f195, f351, f30, f35, f115, f56, f33, f241, f162, f373, f147, f311, f106, f79, f12, f132, f113, f172, f69, f42, f208, f210, f219, f252, f173, f260, f335, f254, f308, f62, f45, f339, f9, f273, f43, f153, f313, f157, f190, f182, f232, f146, f341, f318, f201, f151, f130, f206, f238, f183, f140, f179, f245, f47, f72, f13, f299, f315, f10, f163, f83, f276, f60, f370, f174, f197, f371, f124, f226, f248, f358, f23, f332, f257, f306, f94, f176, f202, f272, f169, f329, f74, f321, f158, f346, f310, f215, f230, f175, f159, f225, f61, f363, f117, f181, f63, f289, f343, f156, f34, f293, f365, f301, f149, f292, f152, f322, f46, f126, f255, f352, f275, f160, f31, f251, f186, f212, f355, f239, f353, f324, f194, f198, f77, f137, f136, f236, f312, f16, f279, f376, f246, f286, f75, f88, f112, f337, f18, f96, f76, f68, f316, f44, f347, f139, f243, f244, f269, f123, f129, f302, f354, f29, f81, f40, f6, f108, f298, f277, f378, f161, f111, f199, f185, f168, f304, f144, f207, f17, f297, f375, f14, f205, f38, f65, f274, f55, f303, f165, f52, f227, f66, f216, f90, f287, f36, f320, f247, f127, f235, f104, f214, f167, f70, f233, f20, f314, f366, f237, f268, f1, f193, f204, f362, f340, f37, f222, f85, f218, f103, f133, f294, f118, f82, f344, f187, f367, f171, f263, f11, f93, f221, f377, f49, f338, f348, f342, f134, f209, f295, f288, f369, f220, f262, f57, f266, f7, f356, f271, f296, f282, f264, f360, f97, f291, f345, f26, f229, f328, f325, f155, f116, f349, f24, f331 in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-dc028e450978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m#print(roc_auc_score(B, y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                           \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                                           \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                                           validate_features=validate_features)\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1541\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378'] []\nexpected f138, f3, f372, f283, f270, f0, f285, f189, f228, f125, f142, f290, f100, f39, f131, f27, f223, f84, f32, f281, f309, f280, f59, f98, f278, f259, f145, f73, f119, f211, f41, f203, f250, f307, f105, f217, f164, f5, f22, f135, f25, f21, f102, f86, f184, f359, f109, f15, f361, f71, f330, f180, f128, f114, f196, f92, f120, f284, f53, f200, f364, f368, f374, f51, f95, f267, f188, f305, f231, f122, f323, f78, f50, f261, f91, f107, f319, f121, f67, f327, f242, f28, f87, f143, f148, f80, f178, f4, f258, f300, f191, f249, f170, f2, f150, f64, f89, f19, f99, f253, f192, f350, f48, f224, f141, f334, f336, f166, f256, f101, f234, f240, f357, f333, f110, f265, f213, f58, f177, f8, f154, f54, f326, f317, f195, f351, f30, f35, f115, f56, f33, f241, f162, f373, f147, f311, f106, f79, f12, f132, f113, f172, f69, f42, f208, f210, f219, f252, f173, f260, f335, f254, f308, f62, f45, f339, f9, f273, f43, f153, f313, f157, f190, f182, f232, f146, f341, f318, f201, f151, f130, f206, f238, f183, f140, f179, f245, f47, f72, f13, f299, f315, f10, f163, f83, f276, f60, f370, f174, f197, f371, f124, f226, f248, f358, f23, f332, f257, f306, f94, f176, f202, f272, f169, f329, f74, f321, f158, f346, f310, f215, f230, f175, f159, f225, f61, f363, f117, f181, f63, f289, f343, f156, f34, f293, f365, f301, f149, f292, f152, f322, f46, f126, f255, f352, f275, f160, f31, f251, f186, f212, f355, f239, f353, f324, f194, f198, f77, f137, f136, f236, f312, f16, f279, f376, f246, f286, f75, f88, f112, f337, f18, f96, f76, f68, f316, f44, f347, f139, f243, f244, f269, f123, f129, f302, f354, f29, f81, f40, f6, f108, f298, f277, f378, f161, f111, f199, f185, f168, f304, f144, f207, f17, f297, f375, f14, f205, f38, f65, f274, f55, f303, f165, f52, f227, f66, f216, f90, f287, f36, f320, f247, f127, f235, f104, f214, f167, f70, f233, f20, f314, f366, f237, f268, f1, f193, f204, f362, f340, f37, f222, f85, f218, f103, f133, f294, f118, f82, f344, f187, f367, f171, f263, f11, f93, f221, f377, f49, f338, f348, f342, f134, f209, f295, f288, f369, f220, f262, f57, f266, f7, f356, f271, f296, f282, f264, f360, f97, f291, f345, f26, f229, f328, f325, f155, f116, f349, f24, f331 in input data"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "from sklearn import cross_validation, tree, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score\n",
    "xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7)\n",
    "\n",
    "y_train_new = train[:,train.shape[1]-1:]\n",
    "X_train = train[:,:train.shape[1]-1]\n",
    "    \n",
    "X_test = test[:,3:]\n",
    "y_train_new = train[:,train.shape[1]-1:]\n",
    "X_train = train[:,:train.shape[1]-1]\n",
    "X_train = X_train[:,3:]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = cross_validation.train_test_split(X_train, y_train_new,test_size=0.2)\n",
    "\n",
    "xgb.fit(X_train, y_train_new)\n",
    "\n",
    "\n",
    "#print(roc_auc_score(B, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(16000, 0), dtype=float64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-23412360736.750458"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "nn = MLPRegressor()\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "nn.fit(X_train, y_train)\n",
    "nn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51733, 1)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.246] [0.]\n",
      "[0.2556] [0.]\n",
      "[0.2614] [0.]\n",
      "[0.2691] [0.]\n",
      "[0.2423] [0.]\n",
      "[0.2643] [0.]\n",
      "[0.2394] [0.]\n",
      "[0.256] [0.]\n",
      "[0.25] [0.]\n",
      "[0.2477] [1.]\n",
      "0.5141380755005418\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "y_train_new = train[:,train.shape[1]-1:]\n",
    "X_train = train[:,:train.shape[1]-1]\n",
    "    \n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X_train, y_train_new,test_size=0.2)\n",
    "n_neighbors = 10000\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors)\n",
    "y_ = knn.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(y_[i], y_test[i])\n",
    "\n",
    "print(roc_auc_score(y_test,y_)  )\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-49e327347488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "y_train_new = train[:,train.shape[1]-1:]\n",
    "X_train = train[:,:train.shape[1]-1]\n",
    "    \n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X_train, y_train_new,test_size=0.2)\n",
    "\n",
    "\n",
    "clf = SVR(kernel='poly')\n",
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgprediction = predictions.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27371597],\n",
       "       [0.11366704],\n",
       "       [0.1329549 ],\n",
       "       ...,\n",
       "       [0.24748915],\n",
       "       [0.02386603],\n",
       "       [0.2097044 ]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgprediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "nn = []\n",
    "with open('nn.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        nn.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_prediction = np.array(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30951509, 0.13851742, 0.14212674, ..., 0.22869109, 0.12686066,\n",
       "       0.30474904])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_prediction = nn_prediction.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_prediction = np.reshape(nn_prediction, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30951509],\n",
       "       [0.13851742],\n",
       "       [0.14212674],\n",
       "       ...,\n",
       "       [0.22869109],\n",
       "       [0.12686066],\n",
       "       [0.30474904]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger = (nn_prediction + xgprediction)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.concatenate((ids, merger), axis=1)\n",
    "np.savetxt('submission.csv', test, delimiter=',', fmt='%1.10f', header = 'id,target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
