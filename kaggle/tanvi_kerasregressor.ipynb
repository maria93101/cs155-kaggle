{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as k_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the AUC metric being used in the competition\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    k_back.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data('data/train_2008.csv', 1)\n",
    "test = load_data('data/test_2008.csv', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[:, :-1]\n",
    "y_train = train[:, -1]\n",
    "\n",
    "x_test = test[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64667, 382)\n",
      "(16000, 382)\n",
      "(64667,)\n"
     ]
    }
   ],
   "source": [
    "# look at the shapes\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = np.concatenate((x_train, x_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80667, 382)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80667, 382)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale x vals, y vals already in range [0,1]\n",
    "sc_X = StandardScaler()\n",
    "merged = sc_X.fit_transform(merged)\n",
    "\n",
    "'''\n",
    "sc_Y = StandardScaler()\n",
    "Y_train = sc_Y.fit_transform(Y)\n",
    "'''\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64667, 382)\n",
      "(16000, 382)\n",
      "(64667,)\n"
     ]
    }
   ],
   "source": [
    "# break up into test and train again\n",
    "x_train = merged[:64667,:]\n",
    "x_test = merged[64667:,:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "def easy_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=easy_model, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.18 (0.04) MSE\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, x_train, y_train, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(x_train, y_train)\n",
    "prediction = estimator.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20077398, 0.03065132, 0.13829222, ..., 0.23666885, 0.11164367,\n",
       "       0.22964296], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.reshape(16000, 1)\n",
    "ids = test[:,:1]\n",
    "ids = ids.astype(int)\n",
    "prediction = prediction.astype(float)\n",
    "test = np.concatenate((ids, prediction), axis=1)\n",
    "\n",
    "np.savetxt('submission.csv', test, delimiter=',', fmt='%1.10f', header = 'id,target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize output data\n",
    "sc_y = StandardScaler()\n",
    "norm_predict = sc_y.fit_transform(prediction)\n",
    "norm_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_predict = norm_predict.reshape(16000, 1)\n",
    "ids = test[:,:1]\n",
    "ids = ids.astype(int)\n",
    "norm_predict = norm_predict.astype(float)\n",
    "out = np.concatenate((ids, norm_predict), axis=1)\n",
    "\n",
    "np.savetxt('norm_submission.csv', out, delimiter=',', fmt='%1.10f', header = 'id,target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try minmaxscaling\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = train[:, :-1]\n",
    "y_train2 = train[:, -1]\n",
    "\n",
    "x_test2 = test[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80667, 382)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged2 = np.concatenate((x_train2, x_test2), axis=0)\n",
    "merged2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_x = MinMaxScaler()\n",
    "merged2 = mm_x.fit_transform(merged2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64667, 382)\n",
      "(16000, 382)\n",
      "(64667,)\n"
     ]
    }
   ],
   "source": [
    "# break up into test and train again\n",
    "x_train2 = merged2[:64667,:]\n",
    "x_test2 = merged2[64667:,:]\n",
    "\n",
    "print(x_train2.shape)\n",
    "print(x_test2.shape)\n",
    "print(y_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model with standardized dataset\n",
    "estimator2 = KerasRegressor(build_fn=easy_model, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.16 (0.00) MSE\n"
     ]
    }
   ],
   "source": [
    "kfold2 = KFold(n_splits=10)\n",
    "results2 = cross_val_score(estimator2, x_train2, y_train2, cv=kfold2)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results2.mean(), results2.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator2.fit(x_train2, y_train2)\n",
    "prediction2 = estimator2.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2 = prediction2.reshape(16000, 1)\n",
    "ids2 = test[:,:1]\n",
    "ids2 = ids2.astype(int)\n",
    "prediction2 = prediction2.astype(float)\n",
    "out2 = np.concatenate((ids2, prediction2), axis=1)\n",
    "\n",
    "np.savetxt('submission.csv', out2, delimiter=',', fmt='%1.10f', header = 'id,target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(prediction2) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize output data\n",
    "sc_y2 = MinMaxScaler()\n",
    "norm_predict2 = sc_y2.fit_transform(prediction2)\n",
    "norm_predict2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_predict2 = norm_predict2.reshape(16000, 1)\n",
    "ids3 = test[:,:1]\n",
    "ids3 = ids3.astype(int)\n",
    "norm_predict2 = norm_predict2.astype(float)\n",
    "out3 = np.concatenate((ids3, norm_predict2), axis=1)\n",
    "\n",
    "np.savetxt('norm_submission.csv', out3, delimiter=',', fmt='%1.10f', header = 'id,target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_prediction2 = estimator2.predict(x_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction2 = estimator2.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = auc(training_prediction2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'auc/update_op:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1487"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(training_prediction2) < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64667,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_prediction2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_tr_predict2 = training_prediction2.reshape(64667, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64667, 1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize output data\n",
    "sc_y2 = MinMaxScaler()\n",
    "norm_tr_predict2 = sc_y2.fit_transform(norm_tr_predict2)\n",
    "norm_tr_predict2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7823736804891283"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train2, norm_tr_predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
