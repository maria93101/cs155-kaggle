{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Load pandas\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/maria/Downloads/train_2008.csv\"\n",
    "filename_test = \"/Users/maria/Downloads/test_2008.csv\"\n",
    "data = np.loadtxt(filename, skiprows=1, delimiter=',')\n",
    "\n",
    "test_data = np.loadtxt(filename_test, skiprows=1, delimiter=',')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (np.asarray(data))[:, 3:382].astype(np.float)\n",
    "y_train = (np.asarray(data))[:, 382].astype(np.float)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# remove first three columns\n",
    "\n",
    "# rename 382th column to did_vote\n",
    "df = df.rename(columns={ df.columns[382]: \"did_vote\" })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (np.asarray(test_data))[:, 3:382].astype(np.float)\n",
    "y_test = (np.asarray(test_data))[:, 381].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_features=2, min_samples_split=4, n_estimators=50, min_samples_leaf=2, max_depth=9)\n",
    "\n",
    "gb = GradientBoostingRegressor(loss='quantile', learning_rate=0.0001, n_estimators=50, max_features='log2', min_samples_split=2, max_depth=1)\n",
    "\n",
    "ada_tree_backing = DecisionTreeRegressor(max_features='sqrt', splitter='random', min_samples_split=4, max_depth=3)\n",
    "\n",
    "ab = AdaBoostRegressor(ada_tree_backing, learning_rate=0.1, loss='square', n_estimators=1000)\n",
    "\n",
    "# validate.cross_v_scores([rf, gb, ab], X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = rf_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_test = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (ids.shape)\n",
    "print (y_predict_test.astype(float).shape)\n",
    "y_predict_test = y_predict_test.reshape(16000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to file\n",
    "ids = test_data[:,:1]\n",
    "ids = ids.astype(int)\n",
    "predictions = y_predict_test.astype(float)\n",
    "out = np.concatenate((ids, predictions), axis=1)\n",
    "\n",
    "np.savetxt('rf_submission.csv', out, delimiter=',', fmt='%1.10f', header = 'id,target')\n",
    "# NOTE: REMEMBER TO REMOVE THE # SYMBOL FROM THE ID HEADER BEFORE SUBMITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = gb.fit(X_train, y_train)\n",
    "y_predict_gb = gb_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train, y_predict_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_model = ab.fit(X_train, y_train)\n",
    "y_predict_ab = gb_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train, y_predict_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = AdaBoostRegressor(base_estimator=rf_model, learning_rate=0.1, loss='square', n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab2_model = ab.fit(X_train, y_train)\n",
    "y_predict_ab2 = gb_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train, y_predict_ab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "X = X_train\n",
    "y = y_train\n",
    "clf = svm.SVR()\n",
    "clf.fit(X, y) \n",
    "# SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "#     gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
    "#     tol=0.001, verbose=False)\n",
    "clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing inputs...\n",
      "Done normalizing. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maria/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, input_shape=(379,), activation=\"sigmoid\", kernel_initializer=\"normal\")`\n",
      "/Users/maria/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:57: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"sigmoid\", kernel_initializer=\"normal\")`\n",
      "/Users/maria/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"sigmoid\", kernel_initializer=\"normal\")`\n",
      "/Users/maria/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"sigmoid\", kernel_initializer=\"normal\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 1000)              380000    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 3,385,002\n",
      "Trainable params: 3,385,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maria/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:67: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64667/64667 [==============================] - 45s 701us/step - loss: 4.0572 - acc: 0.7432\n",
      "Epoch 2/30\n",
      "64667/64667 [==============================] - 33s 514us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 3/30\n",
      "64667/64667 [==============================] - 33s 518us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 4/30\n",
      "64667/64667 [==============================] - 33s 509us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 5/30\n",
      "64667/64667 [==============================] - 33s 507us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 6/30\n",
      "64667/64667 [==============================] - 33s 506us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 7/30\n",
      "64667/64667 [==============================] - 33s 506us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 8/30\n",
      "64667/64667 [==============================] - 33s 504us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 9/30\n",
      "64667/64667 [==============================] - 34s 519us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 10/30\n",
      "64667/64667 [==============================] - 35s 547us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 11/30\n",
      "64667/64667 [==============================] - 32s 494us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 12/30\n",
      "64667/64667 [==============================] - 36s 557us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 13/30\n",
      "64667/64667 [==============================] - 38s 589us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 14/30\n",
      "64667/64667 [==============================] - 38s 585us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 15/30\n",
      "64667/64667 [==============================] - 46s 711us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 16/30\n",
      "64667/64667 [==============================] - 43s 670us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 17/30\n",
      "64667/64667 [==============================] - 42s 655us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 18/30\n",
      "64667/64667 [==============================] - 42s 653us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 19/30\n",
      "64667/64667 [==============================] - 36s 551us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 20/30\n",
      "64667/64667 [==============================] - 37s 577us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 21/30\n",
      "64667/64667 [==============================] - 38s 583us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 22/30\n",
      "64667/64667 [==============================] - 37s 575us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 23/30\n",
      "64667/64667 [==============================] - 37s 580us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 24/30\n",
      "64667/64667 [==============================] - 38s 580us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 25/30\n",
      "64667/64667 [==============================] - 38s 583us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 26/30\n",
      "64667/64667 [==============================] - 38s 581us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 27/30\n",
      "64667/64667 [==============================] - 37s 580us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 28/30\n",
      "64667/64667 [==============================] - 37s 576us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 29/30\n",
      "64667/64667 [==============================] - 37s 577us/step - loss: 4.1163 - acc: 0.7446\n",
      "Epoch 30/30\n",
      "64667/64667 [==============================] - 38s 588us/step - loss: 4.1163 - acc: 0.7446\n",
      "Test loss: 4.11632435783\n",
      "Test accuracy: 0.74461471848\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.regularizers import l1_l2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "filename = \"/Users/maria/Downloads/train_2008.csv\"\n",
    "\n",
    "# load data from CSV files\n",
    "# extract data into data_array by row, first row is column labels\n",
    "with open(filename, 'r') as srcfile:\n",
    "    data_iter = csv.reader(srcfile, quotechar = '\"')\n",
    "    data = [data for data in data_iter]\n",
    "    data = data[1:]\n",
    "    print(data)\n",
    "\n",
    "def normalize(inputs):\n",
    "    print (\"Normalizing inputs...\")\n",
    "    scaler = StandardScaler().fit(inputs)\n",
    "    norm_inputs = scaler.transform(inputs)\n",
    "    print (\"Done normalizing. \")\n",
    "    return (scaler, norm_inputs)\n",
    "\n",
    "# note: two columns removed for x\n",
    "X_train = (np.asarray(data))[:, 3:382].astype(np.float)\n",
    "y_train = (np.asarray(data))[:, 382].astype(np.float)\n",
    "\n",
    "# print(np.shape(X_train))\n",
    "# print(y_train)\n",
    "\n",
    "norm_packet = normalize(X_train)\n",
    "norm_train = norm_packet[1]\n",
    "scaler = norm_packet[0]\n",
    "norm_train = np.array(norm_train)\n",
    "\n",
    "## In your homework you should transform each input data point\n",
    "## into a single vector here and should transform the\n",
    "## labels into a one hot vector using np_utils.to_categorical\n",
    "\n",
    "# our results fall into two categories\n",
    "y_train_hot = np.empty([0, 2])\n",
    "X_train_hot = np.array(X_train)\n",
    "\n",
    "y_train_hot -= 1\n",
    "\n",
    "for i in range(0, y_train.size):\n",
    "    y_train_hot = np.vstack((y_train_hot, to_categorical(y_train[i], 2)))\n",
    "\n",
    "# create our model\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_shape=(379,), init='normal', activation='sigmoid'))\n",
    "model.add(Dense(1000, init='normal', activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1000, init='normal', activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1000, init='normal', activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics=['accuracy'])\n",
    "fit = model.fit(X_train_hot, y_train_hot, batch_size=1000, nb_epoch=30,verbose=1)\n",
    "score = model.evaluate(X_train_hot, y_train_hot, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
