{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "\n",
    "def load_data(filename, skiprows = 1):\n",
    "    '''   \n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\\n\",\n",
    "\n",
    "    Inputs:\n",
    "    filename: given as a string.\n",
    "    Outputs:\\n\",\n",
    "    Data contained in the file, returned as a numpy ndarray\\n\",\n",
    "    '''\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data(\"data/train_2008.csv\")\n",
    "test = load_data(\"data/test_2012.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.08, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.75)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "from sklearn import cross_validation, tree, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score\n",
    "xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7)\n",
    "\n",
    "y_train_new = train[:,train.shape[1]-1:]\n",
    "X_train = train[:,:train.shape[1]-1]\n",
    "    \n",
    "X_test = test[:,3:]\n",
    "y_train_new = train[:,train.shape[1]-1:]\n",
    "X_train = train[:,:train.shape[1]-1]\n",
    "X_train = X_train[:,3:]\n",
    "\n",
    "\n",
    "xgb.fit(X_train, y_train_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03432846]\n",
      " [ 0.10428217]\n",
      " [ 0.10118091]\n",
      " ...\n",
      " [ 0.12150231]\n",
      " [ 0.12071863]\n",
      " [ 0.15512234]]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = test[:,3:]\n",
    "predictions = xgb.predict(X_test)\n",
    "\n",
    "predictions = predictions.reshape(-1, 1)\n",
    "\n",
    "print(predictions)\n",
    "for i in predictions:\n",
    "    if i[0] <0:\n",
    "        i[0] = 0\n",
    "    elif i[0]>1:\n",
    "        i[0] = 1\n",
    "        \n",
    "print(min(predictions))\n",
    "\n",
    "ids = test[:,:1]\n",
    "ids = ids.astype(int)\n",
    "predictions = predictions.astype(float)\n",
    "test = np.concatenate((ids, predictions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('2012_xgb.csv', test, delimiter=',', fmt='%1.10f', header = 'id,target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "xg = []\n",
    "ids = []\n",
    "with open('2012_xgb.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        xg.append(row[1])\n",
    "        ids.append(row[0])\n",
    "xgprediction = np.array(xg[1:])\n",
    "xgprediction = xgprediction.astype(float)\n",
    "xgprediction = np.reshape(xgprediction, (-1, 1))\n",
    "ids = np.array(ids[1:])\n",
    "ids = ids.astype(int)\n",
    "ids = np.reshape(ids, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = []\n",
    "with open('best_nn_2012.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        nn.append(row[1])\n",
    "nnprediction = np.array(nn[1:])\n",
    "nnprediction = nnprediction.astype(float)\n",
    "nnprediction = np.reshape(nnprediction, (-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger = (nnprediction + xgprediction)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05012614],\n",
       "       [0.15135108],\n",
       "       [0.13426292],\n",
       "       ...,\n",
       "       [0.13285747],\n",
       "       [0.11405876],\n",
       "       [0.1500388 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.concatenate((ids, merger), axis=1)\n",
    "np.savetxt('merge_xg_best_nn_2012.csv', test, delimiter=',', fmt='%1.10f', header = 'id,target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
